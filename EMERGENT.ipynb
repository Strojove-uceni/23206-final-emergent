{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/23206-final-emergent/blob/main/EMERGENT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EMERGENT: barcodE iMage EnhanceR usinG dEep Neural neTworks\n",
        "\n",
        "Autoři: Aleksej Gaj, Štěpán Studenovský\n",
        "\n",
        "---\n",
        "Cílem tohoto projektu bylo vytvořit program na rozpoznávání a čtení čárových kodů (EAN13) a 2D kódů (GS1 DataMatrix), který by byl integrovatelný do chytrých zařízení používajících fotoaparát.\n",
        "\n",
        "V současné chvíli existují různé implementace čteček čárových kódů, čtečky GS1 DataMatrix kódů jsou velmi vzácné a citlivé na kvalitu vstupního obrázku (šum, jiné objekty na fotografii, deformace, aj.).\n",
        "\n",
        "Motivací bylo pomocí metod strojového učení a zpracování obrazu předzpracovávat vstupní fotografie (pořizované koncovým uživatelem) pro eliminaci případů, kdy klasické čtečky selžou. Vzniklý algoritmus by měl být snadno uzpůsobitelný pro případ jak čárových, tak i 2D kódů (tj. nezávislý na typu kódu a koncové čtečce).\n",
        "\n",
        "Protože podobných NN-řešení pro klasické čárové kódy existuje celá řada, rozhodli jsme se začít právě u nich. Po vytvoření takového modelu by bylo možné porovnat jeho úspěšnost s jiným řešením. Poté by bylo možné vyzkoušet případ méně populárních GS1 DM kódů.\n",
        "\n"
      ],
      "metadata": {
        "id": "klDLvWCYv5Gz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uvažované přístupy pro konstrukci modelu\n",
        "Volili jsme dva přístupy řešení:\n",
        " - konstrukce a natrénování vlastního **Image2Image** modelu, kde úloha učení by bzla specifikována pouze vhodně zvolenou strukturou sítě a dostatečně bohatým datasetem\n",
        " ``` damaged_img -> NN -> clean_img -> classic_reader ```\n",
        "\n",
        " Tuto cestu jsme zavrhli převážně z časových důvodů\n",
        "\n",
        " - detekce polohy kódu na vstupním obrázku (pomocí **object detection**), manuální vyříznutí (**crop**), a následné odšumění (**denoising** - buď NN modelem, nebo klasickými metodami zpracování obraz. inf.). Zde byly dvě možné varianty:\n",
        " > detekce kódu -> vyříznutí -> denoising -> čtení\n",
        "\n",
        " > denoising -> detekce -> vyříznutí -> čtení\n",
        "\n",
        "\n",
        "\n",
        "K detekci kódu jsme se snažili použít nejprve vlastní síť vytvořenou from scratch se špatnými výsledky, tak jsme zvolili finetunování modelu Yolov5s/m. Vyříznutí jsme napsali simple python skript, který vezme výsledky z yolov5 a vyřízne obrázek.\n",
        "\n",
        "Pro odšumění pomocí NN jsme uvažovali postavit vlastní model typu UNet, ovšem narazili jsme na problém předzpracování (nesjednocená velikost vstupu a výstupu sítě).\n",
        "\n",
        "Proto jsme se vyzkoušeli existující řešení\n",
        "[https://github.com/GunhoChoi/Kind-PyTorch-Tutorial/blob/6e98e475eda6b1a449a8470384a7978462820e52/06_Autoencoder_Model_Save/Autoencoder_Model_Save.ipynb](https://github.com/GunhoChoi/Kind-PyTorch-Tutorial/blob/6e98e475eda6b1a449a8470384a7978462820e52/06_Autoencoder_Model_Save/Autoencoder_Model_Save.ipynb)\n",
        "\n",
        "ale klasické metody se ukázali jako časově i výpočetně snažší:\n",
        "\n",
        "[https://colab.research.google.com/drive/1AaQzDH-BF0Wh6sJkyGIOTdmfJvgw0R72?usp=sharing](https://colab.research.google.com/drive/1AaQzDH-BF0Wh6sJkyGIOTdmfJvgw0R72?usp=sharing)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2hN3pFSbmVPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Existující čtečka kódů (`nice_barcode -> EAN number`)\n",
        "Čtení kódu jsme použili již implementovanou čtečku kódu viz. [https://pypi.org/project/python-barcode/](https://pypi.org/project/python-barcode/)\n",
        "\n",
        "ukázka (vč. čtení kódu a generování datasetu):\n"
      ],
      "metadata": {
        "id": "FPPDeguzjUHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[https://colab.research.google.com/drive/1DNLpUr4CrEb-vmAwVUPcHp9aV0YUUsWo?usp=sharing](https://colab.research.google.com/drive/1DNLpUr4CrEb-vmAwVUPcHp9aV0YUUsWo?usp=sharing)"
      ],
      "metadata": {
        "id": "MrrLQ73bsZPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Výhodou této čtečky je její velmi krátký čas na rozpoznání kódu, vysoká spolehlivost (na kvalitních fotografiích), a odolnost vůči rotaci.\n",
        "\n",
        "Čtečka zmíněných 2D kódů existuje ( [https://github.com/NaturalHistoryMuseum/pylibdmtx/](https://github.com/NaturalHistoryMuseum/pylibdmtx/) ), ovšem žádnou z těchto kvalit nemá. Čtení kódu je pomalé, často neuspěšné a extrémně citlivé na vstupní obrázek."
      ],
      "metadata": {
        "id": "ik5pv1Com5jX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "### Příprava reálného datasetu\n",
        "Pro detekci čárových kódu jsme nejprve připravili datasety, některé již anotované: https://www.kaggle.com/datasets/whoosis/barcode-detection-annotated-dataset, http://artelab.dista.uninsubria.it/downloads/datasets/barcode/medium_barcode_1d/medium_barcode_1d.html,\n",
        "\n",
        "použili jsme ještě jeden dataset ze stránky kaggle.com, kde bylo přibližně 500 obrázků anotovaných  teď již ručně pomocí https://www.makesense.ai/, výborný nastroj pro anotování obrázků pro formát YOLO.\n",
        "\n",
        "Taktéž jsme vyvinuli program pro generování datasetů vhodných pro trénování NN na fotografiích kódů.\n",
        "\n",
        "### Princip generování umělého datasetu:\n",
        " - podle náhodného klíče se vygenerují obrázky čárových kódů\n",
        " - následně jsou zašuměny kombinací Gauss. a Poisson. šumů\n",
        " - poté otočeny o náhodný úhel\n",
        " - zmenšeny a umístěny na jiný, předem zvolený obrázek (sadu obrázků)\n",
        "\n",
        "Výhody:\n",
        " - snadná a rychlá generace i velkých datasetů (10min - 3000ks i víc)\n",
        " - vysoká míra nastavitelnosti parametrů a složitosti\n",
        "  \n",
        "Nevýhody:\n",
        " - není jisté, zda se učení na takovém datasetu bude podobat realitě (ostatně tot byla motivace používat různé datasety)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PoFBfIUVK4qf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ukázka generování datasetu\n",
        "[https://colab.research.google.com/drive/1DNLpUr4CrEb-vmAwVUPcHp9aV0YUUsWo?usp=sharing](https://colab.research.google.com/drive/1DNLpUr4CrEb-vmAwVUPcHp9aV0YUUsWo?usp=sharing)\n",
        "\n",
        "a samotného datasetu:\n",
        "[https://huggingface.co/datasets/aleksejalex/barcodes_temp](https://huggingface.co/datasets/aleksejalex/barcodes_temp)"
      ],
      "metadata": {
        "id": "NGBZCFRpuZXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metodologie\n",
        "\n",
        "Co se detekce čárových kódů a typu úlohy, bylo by nejjednodušší navrhnout nebo použít sítě typu Yolo, fast RNN.... Síť by měla detekovat čárový kód, udělat kolem něj obdélník, pojmenovat třídu, do které jej klasifikovala a poslat výsledek predikce. Taktéž by zaznamenala kde se výřez na fotce vyskytuje pro budoucí vystřihování.\n",
        "\n",
        "Jelikož se jedná o poměrně jednoduchou úlohu detekce jen jedné třídy, tak jsme nejprve zvolili cestu pro vytvoření a natrénování vlastní neuronové sítě v jazyce pytorch-lightning. Trénovali jsme přes Helios na FJFI, dále v colab.google na T4. Vlastní síť se neukázala příliš efektivní, nejspíše by to chtělo mnohem složitější architekturu sítě, vytvořit vlastní loss funkci a hlubší porozumění problému - https://colab.research.google.com/drive/1dq53A7OU2OXf5SzzKatDl7_9VUder5bu?usp=sharing.py.\n",
        "\n",
        "Výsledky trénování a testování jsme ukládali pomocí Weights and Biases.\n",
        "\n",
        "Druhý pokus byl o dotrénování modelu Yolov5s, pokus byl opět neúspěšný. Snaha byla pouze načíst model a vytvořit vlastní přístup a prostředí pro dotrénování - viz AlexNet na cvikách. Nepodařilo se díky nezkušenosti, neschopnosti pracujícího a hlavně díky komplikovanosti modelu implementovat jednotlivé prvky - loss funkci. Odkaz na colab - https://colab.research.google.com/drive/1GKQUOvoa0GSPtYpWARyyaOSIZxiRiaVB?usp=sharing\n",
        "\n",
        "Poslední pokus jsme se věnovali postupu doporučenému od Ultralytics na stránce https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#next-steps. Zde jsme již po další úpravě datových souborů a následování tutoriálu došli k výsledku v https://colab.research.google.com/drive/1Kn7DAfYJPsnvY6c9FK12aPYXOgdDtO0O?usp=sharing. Výsledky trénování se již ukázali jako úspěšné a barcode klasifikoval správně.\n",
        "\n",
        "\n",
        "Vyříznutí obrázku, jsme implemetovali jednoduchý Python skript, který si bere predikovaný .txt/.json výstup z Yolov5 a ořízne obrázek dle klasifikace. https://colab.research.google.com/drive/1tx5v-YymIFhwkDBcqea0apRgVOBslwgE?usp=sharing\n"
      ],
      "metadata": {
        "id": "SqbpTAS98MML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GMAhy6GVS8yX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Závěr\n",
        "Téma této práce bylo motivováno aplikací: v současné době vznikající webová aplikace \"Chytrá lékarnička\" potřebovala robustní a univerzální způsob úpravy fotografií různých kódů pro následné čtení.\n",
        "\n",
        "Ovšem kombinace faktorů, jako\n",
        " - práce na dost abstraktní úloze (zrobustnit existující nástroje)\n",
        " - kombinování několika nástrojů, které ani jeden z členů týmu neuměl ovládat a museli jsme se to naučit \"za pochodu\"\n",
        " - časová tíseň\n",
        "\n",
        "způsobili, že v tuto chvíli nelze předvést demoverzi v podobě funkční pipeline. Avšak výstupy, které můžeme poskytnout, jsou:\n",
        " - autoři mají komplexní představu o doméně, v níž byla úloha formulována, a přehled o existujících postupech a jejich slabinách\n",
        " - několik .ipynb notebooků, ve kterých jsou podrobně sestrojeny a vyzkoušeny jednotlivé prvky výsledného programu, které bohužel z časových důvodů nebylo možné sjednotit\n",
        " - autoři se naučili ovládat technické postupy jako přetrénování YOLOv5, generování umělých obrazových datasetů, techniky odšumování (denoising), aj.\n",
        "\n",
        "\n",
        "\n",
        "Neúspěšnost při sestrojování vlastní NN nebereme za neúspěch, pro úplně první vlastní implementaci NN pro netriviální problém to byl hezký pokus, na kterém jsme se hodně naučili.\n",
        "\n",
        "Do budoucna - projekt nezaniká právě kvůli výše zmíněné motivaci. Tedy  pokračování by mohlo být:\n",
        " - vylepšit architekturu vlastní implementace a zlepšit loss funkci, přidat další parametry\n",
        " - vyzkoušet pokročilé techniky denoising jako např. noise2void ( [https://github.com/juglab/n2v](https://github.com/juglab/n2v) )\n",
        " - do generování umělých datasetů zahrnout i deformace obrazu\n",
        "\n"
      ],
      "metadata": {
        "id": "9NNov9UoT3Lw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cqw2A6lUxOiE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}